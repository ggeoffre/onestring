# SPDX-License-Identifier: GPL-3.0-or-later
# Copyright (C) 2025-2026 ggeoffre, LLC

 █████       ██████████   █████████     ███████     █████████
░░███       ░░███░░░░░█  ███░░░░░███  ███░░░░░███  ███░░░░░███
 ░███        ░███  █ ░  ███     ░░░  ███     ░░███░███    ░░░
 ░███        ░██████   ░███         ░███      ░███░░█████████
 ░███        ░███░░█   ░███    █████░███      ░███ ░░░░░░░░███
 ░███      █ ░███ ░   █░░███  ░░███ ░░███     ███  ███    ░███
 ███████████ ██████████ ░░█████████  ░░░███████░  ░░█████████
░░░░░░░░░░░ ░░░░░░░░░░   ░░░░░░░░░     ░░░░░░░     ░░░░░░░░░


This exercise combines the first three assignments into a fully operational end-to-end solution that logs sensor data through a Flask web API, stores it in MongoDB, retrieves it as CSV, and exposes purge and reporting routes—all driven by refined AI prompts. The goal is to show how small, well-defined Python and Flask “lego pieces” (individual functions, routes, and database helpers) can be snapped together to form a complete working system, perfectly aligned with the CodeMash “Legos” theme of building larger solutions from simple, reusable blocks. By structuring the project into modular Flask routes and separate Mongo utility functions, you learn how to compose functionality cleanly, test each piece independently, and then use the same workflow as earlier: run the code, extract the functions, generate prompts that recreate them, and refine those prompts for higher-quality output. This combined assignment demonstrates how prompt-driven development can scale from isolated components to a functioning data pipeline, while still keeping the tools (Python, Flask, Mongo) simple enough to focus on AI-assisted code generation—not framework complexity.



{
    "recorded" : 1768570200,
    "location" : "den",
    "sensor" : "bmp280",
    "measurement" : "temperature",
    "units" : "C",
    "value" : 22.3
}


I. Start Your Development Environment (recommend using python, flask and mongo):

  1. Launch Docker Desktop, and use the terminal within Docker Desktop to:
    A. Run a mongo database docker container

      docker run --name mongo-container -p 27017:27017 -d mongo:8.2.2

    B. Run a python docker container and attach to the mongo database container

      docker run --name python-container -p 8080:8080 -v ~/Workspace/projects/:/usr/src/python -d python:3.13.5 sleep infinity

  2. Launch VS Code, Open Folder, and Create a Terminal to:
    A. Connect to the python container from the VS Code Terminal

      docker exec -it -w /usr/src/python python-container /bin/bash

  3. Create the following file structure within VS Code:
    ./python/legos
    ./python/legos/flask-app/flask_mongo.py
    ./python/legos/flask-app/app.py
    ./python/legos/flask-app/requirements.txt


II. Before engaging your AI/LLM agent, perform the following tasks leveraging the work from previous tasks:

  1. copy the entire api solution from the previous exercise ./python/api/flask-app into ./python/legos
  2. copy only the mongo_data_access.py, sensor_data_access_protocol.py from the previous exercise ./python/access into ./python/legos
  3. copy only the sensor_data_helper.py from the previous exercise ./python/data into ./python/legos

  NOTE: for #3 above, this code came from "EXTRA PROMPTS TO TRY:" lettter "G" in task 1 "DATA"


III. Modify the following prompts to be language and framework specific (recommend using python and flask):

  1. in each of the three functions of mongo_data_access.py (log_sensor_data, fetch_sensor_data, purge_sensor_data) create a connection to the mongo database, use the same/similar logic for connecting to a mongo database found in the mongo_data.py source file
  2. in the mongo_data_access.py's log_sensor_data, take the "json_data: str" being passed in to the log_sensor_data() function to populate the params of the insert, use the same/similar logic for inserting sensor data into a mongo database found in the mongo_data.py source file
  3. in the mongo_data_access.py's fetch_sensor_data, create a list[str] of JSON strings resulting from the select to a mongo collection as the return for fetch_sensor_data(), use the same/similar logic for selecting sensor data from a mongo database found in the mongo_data.py source file
  4. in the mongo_data_access.py's purge_sensor_data, delete/truncate all data in the sensor data collection, use the same/similar logic for deleting/truncating sensor data from a mongo database found in the mongo_data.py source file
  5. Reuse the OneString helper from earlier tasks for generating, validating, and formatting data. Treat it as a simple utility that can be called directly from the application code.

  NOTE: it is important that mongo_data_access.py continues to strictly conform to the 'sensor_data_access_protocol' as it does now


IV. Run your python Code

  python --version
  pip install --upgrade pip
  pip install -r requirements.txt
  export DATA_HOSTNAME="YOUR_LOACAL_MACHINE_IP_ADDRESS"
  python app.py


V. Once fully operational, copy each of the four functions individually, and add it to the following AI prompt...

  "Using the following source code, generate an AI prompt that would produce this code:"

    compared to...

  "Using the following source code to generate an AI prompt, using simple english, that would produce this code:"

    NOTE: Cute/paste the code you generated above that sucessfully ran.


VI. Now take all of the original prompts from II above, and add it to the following AI prompt...

  "How could each of these prompts be written in a manner to produce 'better' code:"

    NOTE: use any instruction to replace 'better' (like cleaner, efficient, optimized, readable, concise, performant, scalable, maintainable, secure, etc.)


EXTRA PROMPTS:

  A. Using the ABC for sensor_data_access_protocol, implement a method to instantiate a new sensor data access object based on an environment variable.
  B. Implement a better logging mechanism for the sensor data access object.

  Now run the generated code and these prompts back through AI as you did in IV and V previously.


BEYOND FLASK, MONGO & PYTHON:

  Use the same technique for another python framework like django
  Use the same technique for other databases like Postgres, MySQL, Redis and Cassandra
  Use the same technique for other languages and frameworks like Go gin, Java spring, Rust acix and Swift vapor
